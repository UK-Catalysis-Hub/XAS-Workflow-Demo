{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XAS Workflow Task 2\n",
    "\n",
    "This notebook contains the second task of the XAS processing workflow. \n",
    "\n",
    "The break up of the task consist of the following steps \n",
    "\n",
    "|Task                            | Input                                         | Output\n",
    "|-------------                   |-------------                                  |-----  \n",
    "| Curve fitting||\n",
    "| 1. Import data                |File: FeS2_larch.prj                              |\n",
    "| 2. Import Crystal data        |File: FeS2.inp                                 |\n",
    "| 3. Calculate Paths(Atoms+FEFF)||\n",
    "| 4. Set path parameters        | Parameters:                                   |\n",
    "|                                 |    amp  = 1                                   |\n",
    "|                                 |    enot = 0                                   |\n",
    "|                                 |    delr = 0                                   |\n",
    "|                                 |    ss   = 0.003                               |\n",
    "| 5. Select paths                 |                                               |\n",
    "| 6. Run Fit                    |                                               |\n",
    "| 7. Save project               ||\n",
    "| 8. Verify fit results         ||\n",
    "| 8.1 If not OK revise parameners and refit (go to 2.4)||\n",
    "| 8.2 If OK Save project and outputs|                                           |File: FeS2_01.fpj\n",
    "\n",
    "For more details about larch, see https://xraypy.github.io/xraylarch/xafs/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# managing athena files\n",
    "from larch.io import create_athena, read_athena, extract_athenagroup\n",
    "\n",
    "project_name = 'FeS2_larch.prj'\n",
    "\n",
    "fes2_prj = read_athena(project_name)\n",
    "\n",
    "group_keys = list(fes2_prj._athena_groups.keys())\n",
    "\n",
    "group_names = {}\n",
    "\n",
    "for group_key in group_keys:\n",
    "    group_names[group_key] = group_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# required larch modules\n",
    "# calculate pre-edge and post edge for normalisation\n",
    "from larch.xafs import pre_edge\n",
    "# perform background removal\n",
    "from larch.xafs import autobk\n",
    "# calculate fourier transform\n",
    "from larch.xafs import xftf\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    " #######################################################\n",
    "# |         Athena recalculates everything so we      | #\n",
    "# |      need to create a function that calculates    | #\n",
    "# V               all for each new group              V #\n",
    " #######################################################\n",
    "\n",
    "def calc_with_defaults(xafs_group):\n",
    "    # calculate mu and normalise with background extraction\n",
    "    # should let the user specify the colums for i0, it, mu, iR. \n",
    "    if not hasattr(xafs_group, 'mu'):\n",
    "        xafs_group = get_mu(xafs_group)\n",
    "    # calculate pre-edge and post edge and add them to group\n",
    "    # need to read parameters for pre-edge before background calculation with  \n",
    "    # defaul values undo the work of previous step (setting pre-edge limits).\n",
    "    pre_edge(xafs_group, pre1=xafs_group.bkg_params.pre1, pre2=xafs_group.bkg_params.pre2)\n",
    "    #pre_edge(xafs_group)\n",
    "    # perform background removal\n",
    "    autobk(xafs_group) # using defaults so no additional parameters are passed\n",
    "    # calculate fourier transform\n",
    "    xftf(xafs_group)#, kweight=0.5, kmin=3.0, kmax=12.871, dk=1, kwindow='Hanning')\n",
    "    return xafs_group\n",
    "\n",
    "\n",
    " #######################################################\n",
    "# |       The code for plotting Nmu vs E repeats      | #\n",
    "# |   so it is useful to have a plotting function     | #\n",
    "# V            to reduce duplicated code              V #\n",
    " #######################################################\n",
    "# plot mu vs flat normalised mu for selected groups\n",
    "def plot_NxmuE_E_athena_prj(athena_project, group_keys, group_names,\n",
    "                            title = \"Normalised Mu vs E\", xlimits = None,\n",
    "                            ylimits = None):    \n",
    "    # plot mu vs flat normalised mu for selected groups\n",
    "    for group_key in group_keys:\n",
    "        gr_0 = extract_athenagroup(athena_project._athena_groups[group_key])\n",
    "        # recalculate normalisation\n",
    "        calc_with_defaults(gr_0)\n",
    "        plt.plot(gr_0.energy, gr_0.flat, label=group_names[group_key])\n",
    "\n",
    "    # set plot format\n",
    "    plt.xlabel(\"Energy\")\n",
    "    plt.ylabel(\"normalised xmuE\" )\n",
    "    plt.title(title)\n",
    "    plt.grid(linestyle=':', linewidth=1) #show and format grid\n",
    "    if xlimits != None:\n",
    "        plt.xlim(xlimits[0],xlimits[1])\n",
    "    if ylimits != None:\n",
    "        plt.ylim(ylimits[0],ylimits[1])\n",
    "    plt.legend()\n",
    "    return plt, gr_0\n",
    "\n",
    "# plot normalised mu on energy\n",
    "# plot mu vs flat normalised mu for selected groups\n",
    "plt, data_group = plot_NxmuE_E_athena_prj(fes2_prj, group_keys, group_names)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Atoms and FEFF \n",
    "\n",
    "Larch does larch does not include a means for running atoms. Atoms is needed to get input for feff and calculate paths. Currently, the fastest option is to run Artemis to obtain the input (.inp) file for feff from a crystal file ('.cif' or '.inp')\n",
    "\n",
    "The code below shows how subprocess can be used to call perl, execute a small perl script that runs Artemis Atoms, and saves the output file ('inp') in a new directory.\n",
    "\n",
    "The file can then be used to run FEFF from Larch to calculate scattering paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# larch does not include a means for running atoms\n",
    "# need to get input for feff and calculate paths\n",
    "\n",
    "# currently the fastest option is to run Artemis to\n",
    "# obtain the input (.inp) file for feff from a '.cif'\n",
    "# or '.inp' file\n",
    "\n",
    "# get subprocess to run perl script\n",
    "import subprocess\n",
    "\n",
    "# get the input file\n",
    "var = \"FeS2.inp\"\n",
    "\n",
    "retcode = subprocess.call([\"perl\", \"feff_inp.pl\", var])\n",
    "if retcode == 0:\n",
    "    print(\"Passed!\")\n",
    "else:\n",
    "    print(\"Failed!\")\n",
    "\n",
    "# run feff and get the paths\n",
    "from larch.xafs.feffrunner import feff6l\n",
    "#feff6l(folder='.', feffinp='feff.inp', verbose=True)\n",
    "feff6l(folder = './fes2_feff',feffinp='fes2_feff.inp' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Parameters\n",
    "The code for managing the parameters group (GDS in Artemis) is stored in lib/manage_gds.py. \n",
    "\n",
    "The following two cells show how the functions of manage_gds.py are used to read GDS parameters from a file, display the parameters and save them after they have been modified\n",
    "\n",
    "The parameter values are the same used in [Bruce Ravel's example](https://github.com/bruceravel/demeter/tree/master/examples/recipes/FeS2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "209abd7d808640e1acbfe01776d3f1bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sheet(cells=(Cell(column_start=0, row_end=17, row_start=0, squeeze_column=False, squeeze_row=False, value=[['iâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# set parameters          \n",
    "# library containign functions that read and write to csv files\n",
    "import lib.manage_gds as gsdmanager       \n",
    "\n",
    "# define the name of the input gds file\n",
    "gds_file = 'FeS2_gds.csv'\n",
    "# read save parameters from input gds file\n",
    "gds = gsdmanager.read_gds(gds_file)\n",
    "# show gsd group parameters in a spreadsheet\n",
    "this_sheet = gsdmanager.show_gds(gds)\n",
    "# save gsd group parameters in a csv file\n",
    "gsdmanager.save_gds(gds, gds_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the gds data and save it to the csv file\n",
    "gds = gsdmanager.spreadsheet_to_gds(this_sheet)\n",
    "# save gsd group parameters in a csv file\n",
    "gsdmanager.save_gds(gds, gds_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Paths\n",
    "The selection of scattering paths aims at obtaining a list of paths to be used for the fit. For Larch the list must contain specially built *FeffPathGroup* objects. The creation of the path list has been separated in three stages: \n",
    "1. **Show feff paths** and allow selecting the ones to be used\n",
    "2. Show selected paths **Assing parameters** and allow assigning parameters to them\n",
    "3. **Create selected paths list** contating *FeffPathGroup* objects from larch\n",
    "\n",
    "   The goal is to obtain a list of \n",
    "The first activity requires selecting paths from the FEFF directory. These paths are stored by feff in the files.dat\n",
    "\n",
    "Each scattering path is loaded while setting the amplitude, $\\Delta E_0$, $\\Delta R$ and $\\sigma^2$ parameters using the GDS parameters defined previously.\n",
    "\n",
    "The groups are then added to a list of paths to be used for the fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Show all FEFF paths \n",
    "\n",
    "To select a path change the value of the select column to 1 in the table displayed after running the cell below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regular expression matching\n",
    "import re\n",
    "# display editable spreadsheet\n",
    "import ipysheet\n",
    "# File handling\n",
    "from pathlib import Path\n",
    "#library for writing to log\n",
    "import logging\n",
    "\n",
    "# show the paths stored in path files in the FEFF directory.\n",
    "# These paths are stored by feff in the files.dat file\n",
    "def show_feff_paths(var = \"FeS2.inp\"):\n",
    "    crystal_f = Path(var)\n",
    "    feff_dir = crystal_f.name[:-4]+\"_feff\"\n",
    "    feff_inp = crystal_f.name[:-4]+\"_feff.inp\"\n",
    "    feff_files = \"files.dat\"\n",
    "    input_file = Path(feff_dir, feff_files)\n",
    "    #check if feff dir exists\n",
    "    if input_file.parent.exists() and input_file.exists():\n",
    "        logging.info(str(input_file.parent) + \" path and \"+ str(input_file)+ \" found\")\n",
    "    else:\n",
    "        logging.info(str(input_file.parent) + \" path not found, run feff before running select paths\")\n",
    "        return False\n",
    "    count = 0\n",
    "    # the .dat data is stored in fixed width strings \n",
    "    field_widths = [[0,13],[14,21],[22,31],[32,41],[42,48],[49,61]]\n",
    "    is_meta = True\n",
    "    data_headers = []\n",
    "    path_count = 0\n",
    "    paths_data = []\n",
    "    logging.info(\"Reading from: \"+ str(input_file))\n",
    "    with open(input_file) as datfile:\n",
    "        dat_lines = datfile.readlines()\n",
    "        for a_line in dat_lines:\n",
    "            count += 1\n",
    "            if re.match('-*', a_line.strip()).group(0)!= '':\n",
    "                is_meta = False\n",
    "                logging.info(\"{}: {}\".format(count, a_line.strip()))\n",
    "            elif is_meta:\n",
    "                logging.info(\"{}: {}\".format(count, a_line.strip()))\n",
    "            elif data_headers == []:\n",
    "                data_headers = [a_line[s:e].strip().replace(' ','_') for s,e in field_widths]\n",
    "                logging.info(\"headers:\"+ str(data_headers))\n",
    "                data_headers.append('select')\n",
    "                paths_data.append(data_headers)\n",
    "            else:\n",
    "                path_count += 1\n",
    "                data_values = [a_line[s:e].strip() for s,e in field_widths]\n",
    "                data_values.append(0)\n",
    "                data_values[0] = feff_dir+\"/\"+data_values[0]\n",
    "                paths_data.append(data_values)\n",
    "    # use data to populate spreadsheet\n",
    "    \n",
    "    path_sheet = ipysheet.sheet(rows=path_count+1, columns=7)\n",
    "    ipysheet.cell_range(paths_data)\n",
    "    return path_sheet\n",
    "\n",
    "path_sheet = show_feff_paths('FeS2.inp')\n",
    "display(path_sheet)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Assing parameters to paths\n",
    "To define the parameters enter values like those presented in the table below into the spreadsheet that appears after running the code in the following cell. The values should correspond to those defined as GDS parameters previously.\n",
    "\n",
    "|file                  |label | s02 |e0   |sigma2 |deltar      |\n",
    "|----------------------|------|-----|-----|-------|------------|\n",
    "|FeS2_feff/feff0001.dat|S1    |amp  |enot |ss     |alpha\\*reff |\n",
    "|FeS2_feff/feff0002.dat|S2    |amp  |enot |ss2    |alpha\\*reff |\n",
    "|FeS2_feff/feff0003.dat|S3    |amp  |enot |ss3    |alpha\\*reff |\n",
    "|FeS2_feff/feff0004.dat|Fe    |amp  |enot |ssfe   |alpha\\*reff |\n",
    "\n",
    "\n",
    "**Note:** Labelling is used for reference only using Artemis-FEFF given names. Larch's FEFF does not label paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_selected_paths(pats_sheet):\n",
    "    df_sheet = ipysheet.to_dataframe(pats_sheet)\n",
    "    files = []\n",
    "    for f_name, selected in zip(df_sheet[\"A\"], df_sheet[\"G\"]):\n",
    "        if selected == '1':\n",
    "            files.append(f_name)    \n",
    "\n",
    "    sel_paths_data = [[0 for col in range(6)] for row in range(4)]\n",
    "    sel_paths_data[:0]=[['file','label','s02','e0','sigma2','deltar']]\n",
    "    ps_row = 1\n",
    "    for a_name in files:\n",
    "        sel_paths_data[ps_row][0] = a_name\n",
    "        ps_row += 1\n",
    "\n",
    "    sp_sheet = ipysheet.sheet(rows=len(files)+1, columns=6)\n",
    "    ipysheet.cell_range(sel_paths_data)\n",
    "    display(sp_sheet)\n",
    "    return sp_sheet\n",
    "sp_sheet = show_selected_paths(path_sheet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library containign functions that read and write to csv files\n",
    "import lib.handle_csv as csvhandler\n",
    "\n",
    "# use data frame to create selected paths list\n",
    "def build_selected_paths_list(sp_sheet):\n",
    "    df_sheet = ipysheet.to_dataframe(sp_sheet).transpose()\n",
    "    sp_list = []\n",
    "    for col in df_sheet:\n",
    "        if df_sheet[col][0] != 'file':\n",
    "            new_path = lp.xafs.FeffPathGroup(filename = df_sheet[col][0],\n",
    "                                             label    = df_sheet[col][1],\n",
    "                                             s02      = df_sheet[col][2],\n",
    "                                             e0       = df_sheet[col][3],\n",
    "                                             sigma2   = df_sheet[col][4],\n",
    "                                             deltar   = df_sheet[col][5],\n",
    "                                             _larch   = session)\n",
    "            sp_list.append(new_path)\n",
    "    return sp_list\n",
    "\n",
    "def save_selected_paths_list(sp_sheet, f_prefix = \"FeS2\"):\n",
    "    # it is easier to transpose as dataframes main objects are columns\n",
    "    df_sheet = ipysheet.to_dataframe(sp_sheet).transpose()\n",
    "    sp_list = {}\n",
    "    path_count = 1\n",
    "    for col in df_sheet:\n",
    "        if df_sheet[col][0] != 'file':\n",
    "            sp_list[path_count] = {'id': path_count,\n",
    "                                   'filename':df_sheet[col][0],\n",
    "                                   'label':df_sheet[col][1],\n",
    "                                   's02':df_sheet[col][2],\n",
    "                                   'e0':df_sheet[col][3],\n",
    "                                   'sigma2':df_sheet[col][4],\n",
    "                                   'deltar':df_sheet[col][5]}\n",
    "            path_count += 1\n",
    "    print(sp_list)\n",
    "    file_name = f_prefix+\"_sp.csv\"\n",
    "    csvhandler.write_csv_data(sp_list,file_name)\n",
    "    \n",
    "f_prefix = \"FeS2\"\n",
    "selected_paths = build_selected_paths_list(sp_sheet)\n",
    "save_selected_paths_list(sp_sheet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Fit\n",
    "\n",
    "XAS fitting is performed in three steps:\n",
    "1. Create a Transform group to holds the set of Fourier transform parameters, fitting ranges, and space in which the data and sum of paths are to be compared (R space)\n",
    "2. Create a Dataset group,consistaining of the three components required for fitting(data, paths, and transform group)\n",
    "3. FEFFIT is run with the list of parameters (gds) for the fit, and the dataset or list of datasets groups.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run fit\n",
    "# create the transform grup (prepare the fit space).\n",
    "trans = lp.xafs.TransformGroup(fitspace='r', kmin=3, kmax=14, kw=2, dk=1, window='hanning', rmin=1.4,\n",
    "                               rmax=3.0, _larch=session)\n",
    "\n",
    "dset = lp.xafs.FeffitDataSet(data=data_group, pathlist=selected_paths, transform=trans, _larch=session)\n",
    "\n",
    "out = lp.xafs.feffit(gds, dset, _larch=session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review fit results\n",
    "The results of the fit are stored in the dataset. These can be plotted and printed as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(dset.data.r, dset.data.chir_mag, color='b')\n",
    "plt.plot(dset.data.r, dset.data.chir_re, color='b', label='expt.')\n",
    "plt.plot(dset.model.r, dset.model.chir_mag, color='r')\n",
    "plt.plot(dset.model.r, dset.model.chir_re, color='r', label='fit')\n",
    "plt.ylabel(\"Magnitude of Fourier Transform of $k^2 \\cdot \\chi$/$\\mathrm{\\AA}^{-3}$\")\n",
    "plt.xlabel(\"Radial distance/$\\mathrm{\\AA}$\")\n",
    "plt.xlim(0, 5)\n",
    "\n",
    "plt.fill([1.4, 1.4, 3.0, 3.0],[-3, 3, 3, -3], color='g',alpha=0.1)\n",
    "plt.text(2.35, -2.5, 'fit range')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 4))\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax2 = fig.add_subplot(122)\n",
    "# Creating the chifit plot from scratch\n",
    "#from larch.wxlib.xafsplots import plot_chifit\n",
    "#plot_chifit(dset, _larch=session)\n",
    "ax1.plot(dset.data.k, dset.data.chi*dset.data.k**2, color='b', label='expt.')\n",
    "ax1.plot(dset.model.k, dset.model.chi*dset.data.k**2 , color='r', label='fit')\n",
    "ax1.set_xlim(0, 15)\n",
    "ax1.set_xlabel(\"$k (\\mathrm{\\AA})^{-1}$\")\n",
    "ax1.set_ylabel(\"$k^2$ $\\chi (k)(\\mathrm{\\AA})^{-2}$\")\n",
    "ax1.fill([3.0, 3.0, 14.0, 14.0],[-3, 3, 3, -3], color='g',alpha=0.1)\n",
    "ax1.text(12.35, -2.5, 'fit range')\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(dset.data.r, dset.data.chir_mag, color='b', label='expt.')\n",
    "ax2.plot(dset.model.r, dset.model.chir_mag, color='r', label='fit')\n",
    "ax2.set_xlim(0, 5)\n",
    "ax2.set_xlabel(\"$R(\\mathrm{\\AA})$\")\n",
    "ax2.set_ylabel(\"$|\\chi(R)|(\\mathrm{\\AA}^{-3})$\")\n",
    "ax2.legend(loc='upper right')\n",
    "ax2.fill([1.4, 1.4, 3.0, 3.0],[0, 3, 3, 0], color='g',alpha=0.1)\n",
    "ax2.text(2.35, 2.75, 'fit range')\n",
    "plt.show()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lp.xafs.feffit_report(out, _larch=session))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
