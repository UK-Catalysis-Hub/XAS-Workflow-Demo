{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XAS Workflow Task 2\n",
    "\n",
    "This notebook contains the second task of the XAS processing workflow. \n",
    "\n",
    "The break up of the task consist of the following steps \n",
    "\n",
    "|Task                            | Input                                         | Output\n",
    "|-------------                   |-------------                                  |-----  \n",
    "| Curve fitting||\n",
    "| 1. Import data                |File: FeS2_larch.prj                              |\n",
    "| 2. Import Crystal data        |File: FeS2.inp                                 |\n",
    "| 3. Calculate Paths(Atoms+FEFF)||\n",
    "| 4. Set path parameters        | Parameters:                                   |\n",
    "|                                 |    amp  = 1                                   |\n",
    "|                                 |    enot = 0                                   |\n",
    "|                                 |    delr = 0                                   |\n",
    "|                                 |    ss   = 0.003                               |\n",
    "| 5. Select paths                 |                                               |\n",
    "| 6. Run Fit                    |                                               |\n",
    "| 7. Save project               ||\n",
    "| 8. Verify fit results         ||\n",
    "| 8.1 If not OK revise parameners and refit (go to 2.4)||\n",
    "| 8.2 If OK Save project and outputs|                                           |File: FeS2_01.fpj\n",
    "\n",
    "For more details about larch, see https://xraypy.github.io/xraylarch/xafs/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries\n",
    "Libraries required for running fit on the XAS data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# managing athena files\n",
    "from larch.io import create_athena, read_athena, extract_athenagroup\n",
    "# calculate pre-edge and post edge for normalisation\n",
    "from larch.xafs import pre_edge\n",
    "# perform background removal\n",
    "from larch.xafs import autobk\n",
    "# calculate fourier transform\n",
    "from larch.xafs import xftf\n",
    "\n",
    "from larch import Interpreter\n",
    "import larch_plugins as lp\n",
    "\n",
    "# File handling\n",
    "from pathlib import Path\n",
    "\n",
    "#plotting library\n",
    "#%matplotlib inline\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "# subprocess library used to run perl script\n",
    "import subprocess\n",
    "\n",
    "#library for writing to log\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Functions\n",
    "\n",
    "The following cell contains the defined functions (methods) for processing XAS files.\n",
    "\n",
    "- **set_logger** intialises the logging.\n",
    "- **get_files_list** returns a list of files in the directory matching the given file pattern.\n",
    "- **calc_with_defaults ** recalculates mu, normal, pre-edge for each group being processed.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    " #######################################################\n",
    "# |                Initialise log file                | #\n",
    "# V  provide the path and name of the log file to use V #\n",
    " #######################################################\n",
    "    \n",
    "def set_logger(log_file):\n",
    "    logger = logging.getLogger()\n",
    "    fhandler = logging.FileHandler(filename=log_file, mode='a')\n",
    "    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "    fhandler.setFormatter(formatter)\n",
    "    logger.addHandler(fhandler)\n",
    "    # prevent matplotlib font manager from writing to log\n",
    "    logging.getLogger('matplotlib.font_manager').disabled = True\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "\n",
    " #######################################################\n",
    "# |                  Get a list of files              | #\n",
    "# V       provide the path and pattern to match       V #\n",
    " #######################################################\n",
    "    \n",
    "#reading all files with the same extension files from a dir\n",
    "def get_files_list(source_dir, f_pattern):\n",
    "    i_counter = 0\n",
    "    files_list = []\n",
    "    for filepath in sorted(source_dir.glob(f_pattern)):\n",
    "        i_counter += 1\n",
    "        files_list.append(filepath)\n",
    "    return files_list\n",
    "\n",
    " #######################################################\n",
    "# |         Athena recalculates everything so we      | #\n",
    "# |      need to create a function that calculates    | #\n",
    "# V               all for each new group              V #\n",
    " #######################################################\n",
    "\n",
    "def calc_with_defaults(xafs_group):\n",
    "    # calculate mu and normalise with background extraction\n",
    "    # should let the user specify the colums for i0, it, mu, iR. \n",
    "    if not hasattr(xafs_group, 'mu'):\n",
    "        xafs_group = get_mu(xafs_group)\n",
    "    # calculate pre-edge and post edge and add them to group\n",
    "    # need to read parameters for pre-edge before background calculation with  \n",
    "    # defaul values undo the work of previous step (setting pre-edge limits).\n",
    "    pre_edge(xafs_group, pre1=xafs_group.bkg_params.pre1, pre2=xafs_group.bkg_params.pre2)\n",
    "    #pre_edge(xafs_group)\n",
    "    # perform background removal\n",
    "    autobk(xafs_group) # using defaults so no additional parameters are passed\n",
    "    # calculate fourier transform\n",
    "    xftf(xafs_group)#, kweight=0.5, kmin=3.0, kmax=12.871, dk=1, kwindow='Hanning')\n",
    "    return xafs_group\n",
    "\n",
    "\n",
    " #######################################################\n",
    "# |       The code for plotting Nmu vs E repeats      | #\n",
    "# |   so it is useful to have a plotting function     | #\n",
    "# V            to reduce duplicated code              V #\n",
    " #######################################################\n",
    "# plot flat normalised mu vs Energy for selected groups\n",
    "def plot_Nxmu_E(athena_project, group_keys, group_names,\n",
    "                            title = \"Normalised $\\mu$ vs E\", xlimits = None,\n",
    "                            ylimits = None):    \n",
    "    # plot mu vs flat normalised mu for selected groups\n",
    "    for group_key in group_keys:\n",
    "        gr_0 = extract_athenagroup(athena_project._athena_groups[group_key])\n",
    "        # recalculate normalisation\n",
    "        calc_with_defaults(gr_0)\n",
    "        plt.plot(gr_0.energy, gr_0.flat, label=group_names[group_key])\n",
    "\n",
    "    # set plot format\n",
    "    plt.xlabel(\"Energy\")\n",
    "    plt.ylabel(\"Normalised $\\mu$\" )\n",
    "    plt.title(title)\n",
    "    plt.grid(linestyle=':', linewidth=1) #show and format grid\n",
    "    if xlimits != None:\n",
    "        plt.xlim(xlimits[0],xlimits[1])\n",
    "    if ylimits != None:\n",
    "        plt.ylim(ylimits[0],ylimits[1])\n",
    "    plt.legend()\n",
    "    return plt, gr_0\n",
    "\n",
    " ########################################################\n",
    "# |                Get scattering paths                | #\n",
    "# | larch does not include a means for running atoms   | #\n",
    "# | need to get input for feff and calculate paths     | #\n",
    "# | currently the fastest option is to run Artemis to  | #\n",
    "# | obtain the input (.inp) file for feff from a '.cif'| #\n",
    "# V or '.inp' file                                     V #\n",
    " ########################################################\n",
    "def run_feff(var = \"FeS2.inp\"):\n",
    "    crystal_f = Path(var)\n",
    "    feff_dir = crystal_f.name[:-4]+\"_feff\"\n",
    "    feff_inp = crystal_f.name[:-4]+\"_feff.inp\"\n",
    "    retcode = subprocess.call([\"perl\", \"feff_inp.pl\", var, feff_dir, feff_inp])\n",
    "    if retcode == 0:\n",
    "        print(\"Passed!\")\n",
    "    else:\n",
    "        print(\"Failed!\")\n",
    "\n",
    "    # run feff and get the paths\n",
    "    from larch.xafs.feffrunner import feff6l\n",
    "    #feff6l(folder='.', feffinp='feff.inp', verbose=True)\n",
    "    feff6l(folder = feff_dir, feffinp=feff_inp)\n",
    " ########################################################\n",
    "# |                Read GDS parameters                 | #\n",
    "# | read parameters from gds file                      | #\n",
    "# | each line contains a parameter defined as          | #\n",
    "# V type name = value                                  V #\n",
    " ########################################################\n",
    "# guess amp = 1.00000\n",
    "# guess enot = 0\n",
    "# skip delr = 0\n",
    "# guess ss = 0.00300\n",
    "# guess alpha = 0\n",
    "# guess ss2 = 0.00300\n",
    "# guess ss3 = ss2\n",
    "# guess ssFe = 0.00300\n",
    "# skip ss4 = 0.00300\n",
    "##############################\n",
    "def read_gds(gds_file = \"FeS2_dmtr.gds\"):\n",
    "    session = Interpreter()\n",
    "    dgs_group = lp.fitting.param_group(_larch=session)\n",
    "    with open('FeS2_dmtr.gds', 'r') as reader:\n",
    "        # Read and print the entire file line by line\n",
    "        gds_par = reader.readline()\n",
    "        while gds_par != '':  # The EOF char is an empty string\n",
    "            gds_par_def = gds_par.split()\n",
    "            #gds file structure:\n",
    "            # type name = value\n",
    "            gds_type = gds_par_def[0]\n",
    "            gds_name = gds_par_def[1]\n",
    "            gds_val = 0.0\n",
    "            gds_exp = \"\"\n",
    "            #print(gds_par_def, \"\\n\", end='')\n",
    "            try:\n",
    "                gds_val = float(gds_par_def[3])\n",
    "            except ValueError:\n",
    "                #print(\"Not a float value\")\n",
    "                gds_val = 0.00\n",
    "                gds_exp = gds_par_def[3]\n",
    "            one_par = None\n",
    "            if gds_type == \"guess\":\n",
    "                one_par = lp.fitting.guess(name=gds_name ,value=gds_val, vary=True, expr=gds_exp )\n",
    "            elif gds_type == \"def\":\n",
    "                one_par = lp.fitting.param(name=gds_name ,value=gds_val, vary=False, expr=gds_exp )\n",
    "            if one_par != None:\n",
    "                 dgs_group.__setattr__(gds_par_def[1],one_par )\n",
    "            gds_par = reader.readline()\n",
    "    return dgs_group\n",
    "      \n",
    "# show plot of normalised data\n",
    "def plot_normalised(xafs_group):\n",
    "        plt.plot(xafs_group.energy, xafs_group.mu, label=xafs_group.filename) # plot mu in blue\n",
    "        plt.grid(color='r', linestyle=':', linewidth=1) #show and format grid\n",
    "        plt.xlabel('Energy (eV)') # label y graph\n",
    "        plt.ylabel('x$\\mu$(E)') # label y axis\n",
    "        plt.title(\"pre-edge and post_edge fitting to $\\mu$\")\n",
    "        plt.legend() # show legend\n",
    "        return plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input parameters (variables)\n",
    "\n",
    "The variables in the next cell indicate where to get the data from, the pattern of the files to process and the number of files to process. These can be changed to process different datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables that can be changed to process different datasets\n",
    "data_path = \".\\\\rh4co\\\\\"\n",
    "file_pattern = \"*.prj\"\n",
    "f_prefix = \"rh4co\"\n",
    "crystal_file = \"..\\\\cif_files\\\\C12O12Rh4.cif\" #\"FeS2.inp\"\n",
    "gds_parms_f = \"rh4co.gds\"\n",
    "sel_paths_f = \"rh4co.csv\"\n",
    "top_count = 4\n",
    "show_graph = True # False to prevent showing graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main function\n",
    "The code in the cell below performs the bulk of the processing for task 2 calling functions defined above and using the input parameters.\n",
    "\n",
    "The three operations for generating paths, selecting paths and defining parameters are performed once before processing the input files in the list\n",
    "\n",
    "### Generate paths \n",
    "Larch does larch does not include a means for running **Atoms**. Atoms is needed to get input for **FEFF** and calculate paths. Currently, the fastest option is to run Artemis to obtain the input (.inp) file for FEFF from a crystal file ('.cif' or '.inp').\n",
    "\n",
    "The run_feff function, defined above, uses the subprocess library to call perl to execute a script that runs Artemis Atoms, and saves the output file ('.inp') in a new directory. The file is then be used to run FEFF from Larch to calculate scattering paths.\n",
    "\n",
    "### Set Parameters\n",
    "\n",
    "The read_gds function, defined above, creates the parameters group (GDS in Artemis) from a gds file. The code uses lp.fitting.param_group and lp.fitting.param instead of importing Group and Parameter (does not work with Jupyter). The parameter values are read from a text file.\n",
    "\n",
    "### Select Paths\n",
    "The selection of scattering paths is handled by the read_paths function. Each scattering path is loaded while setting the amplitude, $\\Delta E_0$, $\\Delta R$ and $\\sigma^2$ parameters using the GDS parameters defined previously. The groups are then added returned as a list of paths to be used for the fits.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root] INFO : Started processing\n",
      "[root] INFO : Input variables:\n",
      "[root] INFO : \tdata_path    = .\\rh4co\\\n",
      "[root] INFO : \tfile_pattern = *.prj\n",
      "[root] INFO : \tf_prefix     = rh4co\n",
      "[root] INFO : \tcrystal_file = ..\\cif_files\\C12O12Rh4.cif\n",
      "[root] INFO : \ttop_count    = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rh4co_fit\\process.log\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root] INFO : GDS Parameters read OK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed!\n",
      " : ======== running Feff module C:\\Users\\scman1\\Anaconda3\\envs\\python36\\lib\\site-packages\\larch\\bin\\win32\\feff6l.exe ========\n",
      " : Feff 6L.02\n",
      " : Rh4 (C O)12\n",
      " : Wei, C.H.\n",
      " : Structural analyses of tetracobalt dodecacarbonyl and tetrarhodium\n",
      " : dodecacarbonyl. crystallographic treatments of a disordered structure and\n",
      " : a twinned composite\n",
      " : Calculating potentials and phases...\n",
      " : free atom potential and density for atom type    0\n",
      " : free atom potential and density for atom type    1\n",
      " : free atom potential and density for atom type    2\n",
      " : free atom potential and density for atom type    3\n",
      " : overlapped potential and density for unique potential    0\n",
      " : overlapped potential and density for unique potential    1\n",
      " : overlapped potential and density for unique potential    2\n",
      " : overlapped potential and density for unique potential    3\n",
      " : muffin tin radii and interstitial parameters\n",
      " : phase shifts for unique potential    0\n",
      " : phase shifts for unique potential    1\n",
      " : phase shifts for unique potential    2\n",
      " : phase shifts for unique potential    3\n",
      " : Preparing plane wave scattering amplitudes...\n",
      " : nncrit in prcrit       9\n",
      " : Searching for paths...\n",
      " : Rmax  5.0000  keep and heap limits   0.0000000   0.0000000\n",
      " : Preparing neighbor table\n",
      " : nfound  nheap  nheapx  nsc    r\n",
      " : Paths found      403   (nheapx, nbx      99   8)\n",
      " : Eliminating path degeneracies...\n",
      " : Plane wave chi amplitude filter   2.50%\n",
      " : Unique paths    115,  total paths     177\n",
      " : Calculating EXAFS parameters...\n",
      " : Curved wave chi amplitude ratio   4.00%\n",
      " : Discard feff.dat for paths with cw ratio <   2.67%\n",
      " : path  cw ratio     deg    nleg  reff\n",
      " : 1   100.000     1.000     2   1.9149\n",
      " : 2    91.295     1.000     2   1.9854\n",
      " : 3    83.637     1.000     2   2.0550\n",
      " : 4    79.929     1.000     2   2.0917\n",
      " : 5    89.367     1.000     2   2.7050\n",
      " : 6    86.941     1.000     2   2.7337\n",
      " : 7    81.971     1.000     2   2.7957\n",
      " : 8    37.159     1.000     2   3.0163\n",
      " : 9   100.000     2.000     3   3.0167\n",
      " : 10    76.145     1.000     4   3.0170\n",
      " : 11    32.597     1.000     2   3.0220\n",
      " : 12    29.179     1.000     2   3.1366\n",
      " : 13    25.921     2.000     3   3.1653\n",
      " : 14    27.950     1.000     2   3.1819\n",
      " : 15    58.926     2.000     3   3.2132\n",
      " : 16    32.939     1.000     4   3.2445\n",
      " : 17    21.901     2.000     3   3.2875\n",
      " : 18     7.728     1.000     4   3.3087\n",
      " : 19     5.677     2.000     3   3.3214\n",
      " : 20     5.763     2.000     3   3.3260\n",
      " : 21     6.231     1.000     4   3.4384\n",
      " : 22     2.425     2.000     3   3.4558 neglected\n",
      " : 23    16.232     1.000     2   3.5372\n",
      " : 24     3.728     2.000     3   3.5425\n",
      " : 25    15.819     1.000     2   3.5671\n",
      " : 26     3.312     2.000     3   3.5939\n",
      " : 27     4.223     2.000     3   3.6181\n",
      " : 28     2.572     2.000     3   3.6489 neglected\n",
      " : 29    14.227     1.000     2   3.6920\n",
      " : 30    11.517     2.000     3   3.8220\n",
      " : 31     4.455     1.000     4   3.8297\n",
      " : 32    12.091     1.000     2   3.8888\n",
      " : 33    15.264     2.000     4   3.9003\n",
      " : 34    14.184     1.000     2   3.9535\n",
      " : 35     3.684     1.000     4   3.9708\n",
      " : 36    10.240     1.000     4   3.9783\n",
      " : 37    32.052     2.000     5   3.9787\n",
      " : 38    25.210     1.000     6   3.9790\n",
      " : 39    11.124     1.000     2   3.9920\n",
      " : 40    13.715     1.000     2   3.9945\n",
      " : 41     8.332     2.000     3   4.0838\n",
      " : 42     3.048     2.000     3   4.0890\n",
      " : 43     3.260     2.000     3   4.1013\n",
      " : 44     3.073     1.000     4   4.1100\n",
      " : 45     7.914     2.000     3   4.1209\n",
      " : 46     3.206     2.000     3   4.1223\n",
      " : 47     2.799     1.000     4   4.1834\n",
      " : 48     7.874     2.000     3   4.1912\n",
      " : 49     1.425     2.000     3   4.2145 neglected\n",
      " : 50     8.949     1.000     2   4.2696\n",
      " : 51    10.748     1.000     2   4.3002\n",
      " : 52    10.714     1.000     2   4.3043\n",
      " : 53    10.621     1.000     2   4.3155\n",
      " : 54     7.182     2.000     3   4.3251\n",
      " : 55     5.235     1.000     4   4.3347\n",
      " : 56     1.577     2.000     3   4.3415 neglected\n",
      " : 57     3.558     1.000     4   4.3452\n",
      " : 58     8.350     1.000     2   4.3603\n",
      " : 59    12.514     2.000     5   4.3660\n",
      " : 60    16.294     2.000     3   4.3787\n",
      " : 61     1.866     2.000     3   4.3964 neglected\n",
      " : 62     7.648     1.000     6   4.3972\n",
      " : 63     6.643     2.000     3   4.4001\n",
      " : 64    13.337     2.000     3   4.4055\n",
      " : 65     2.179     2.000     4   4.4289 neglected\n",
      " : 66     5.926     2.000     3   4.4541\n",
      " : 67     1.929     2.000     4   4.4805 neglected\n",
      " : 68     9.336     1.000     2   4.4832\n",
      " : 69     7.222     1.000     4   4.4878\n",
      " : 70     4.653     2.000     5   4.4886\n",
      " : 71    12.751     2.000     3   4.4927\n",
      " : 72     5.932     1.000     4   4.4955\n",
      " : 73     2.547     2.000     5   4.5045 neglected\n",
      " : 74     2.232     2.000     4   4.5397 neglected\n",
      " : 75     2.262     2.000     5   4.5559 neglected\n",
      " : 76     1.888     2.000     3   4.5571 neglected\n",
      " : 77     1.544     2.000     3   4.5599 neglected\n",
      " : 78     3.284     2.000     3   4.5615\n",
      " : 79     2.902     2.000     3   4.5732\n",
      " : 80     3.436     2.000     3   4.6064\n",
      " : 81     4.653     1.000     4   4.6251\n",
      " : 82     6.854     2.000     3   4.6311\n",
      " : 83     6.727     1.000     2   4.6507\n",
      " : 84     8.204     1.000     2   4.6551\n",
      " : 85     2.780     2.000     3   4.6567\n",
      " : 86     2.354     1.000     4   4.6601 neglected\n",
      " : 87     3.264     2.000     3   4.6645\n",
      " : 88     6.619     1.000     2   4.6730\n",
      " : 89     3.068     2.000     4   4.6823\n",
      " : 90     1.803     2.000     4   4.7108 neglected\n",
      " : 91    18.587     2.000     3   4.7211\n",
      " : 92    13.756     1.000     4   4.7692\n",
      " : 93     2.182     1.000     4   4.7791 neglected\n",
      " : 94     6.951     2.000     3   4.7831\n",
      " : 95     6.102     2.000     3   4.7842\n",
      " : 96     2.095     2.000     4   4.7887 neglected\n",
      " : 97     2.457     2.000     4   4.7891 neglected\n",
      " : 98    10.393     2.000     4   4.7967\n",
      " : 99     2.759     2.000     5   4.8110\n",
      " : 100     0.984     2.000     3   4.8201 neglected\n",
      " : 101     1.949     2.000     4   4.8507 neglected\n",
      " : 102     7.049     1.000     2   4.8622\n",
      " : 103     2.435     2.000     3   4.8868 neglected\n",
      " : 104     6.792     1.000     2   4.9136\n",
      " : 105     5.690     2.000     3   4.9161\n",
      " : 106     2.369     1.000     4   4.9155 neglected\n",
      " : 107    11.074     2.000     3   4.9167\n",
      " : 108    10.137     2.000     4   4.9368\n",
      " : 109     5.170     1.000     6   4.9403\n",
      " : 110    16.546     2.000     7   4.9407\n",
      " : 111    13.280     1.000     8   4.9410\n",
      " : 112     3.562     2.000     3   4.9549\n",
      " : 113     5.689     2.000     4   4.9593\n",
      " : 114     5.096     1.000     4   4.9712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root] INFO : Completed FEFF\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " : 115     6.492     1.000     2   4.9766\n",
      " : 94 paths kept,  115 examined.\n",
      " : Feff done.  Have a nice day.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-37e64497b432>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[1;31m# plot mu vs flat normalised mu for selected groups\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;31m#plt, data_group = plot_Nxmu_E(data_prj, group_keys, group_names)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mplt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplot_normalised\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_group\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-27fe6cf3dc14>\u001b[0m in \u001b[0;36mplot_normalised\u001b[1;34m(xafs_group)\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[1;31m# show plot of normalised data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mplot_normalised\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxafs_group\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 152\u001b[1;33m        \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxafs_group\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menergy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxafs_group\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxafs_group\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# plot mu in blue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    153\u001b[0m        \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlinestyle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m':'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlinewidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#show and format grid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m        \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Energy (eV)'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# label y graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# create the path for storing results\n",
    "base_path = Path(\"./\" , f_prefix+\"_fit\")\n",
    "Path(base_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "log_file = Path(\"./\",base_path,\"process.log\")\n",
    "print(log_file)\n",
    "# set path for log\n",
    "set_logger(log_file)\n",
    "\n",
    "# get the list of files to process\n",
    "source_path = Path(data_path)\n",
    "files_list = get_files_list(source_path, file_pattern)\n",
    "xas_data = {}\n",
    "\n",
    "logging.info(\"Started processing\")\n",
    "logging.info(\"Input variables:\")\n",
    "logging.info(\"\\tdata_path    = \" + data_path)\n",
    "logging.info(\"\\tfile_pattern = \" + file_pattern)\n",
    "logging.info(\"\\tf_prefix     = \" + f_prefix)\n",
    "logging.info(\"\\tcrystal_file = \" + crystal_file)\n",
    "logging.info(\"\\ttop_count    = \" + str(top_count))\n",
    "\n",
    "# read the gds parameters from input file\n",
    "gds = read_gds(gds_parms_f)\n",
    "logging.info(\"GDS Parameters read OK\")\n",
    "\n",
    "# run feff on crystal file to generate scattering paths\n",
    "run_feff(crystal_file)\n",
    "logging.info(\"Completed FEFF\")\n",
    "# read the selected paths list to access relevant paths \n",
    "# generated from FEFF\n",
    "#selected_paths = read_paths(sel_paths_f)\n",
    "\n",
    "# counter for break\n",
    "i_count = 0\n",
    "for a_file in files_list:\n",
    "    project_name = a_file.name\n",
    "    data_prj = read_athena(a_file)\n",
    "    group_keys = list(data_prj._athena_groups.keys())\n",
    "\n",
    "    #group_names = {}\n",
    "\n",
    "    #for group_key in group_keys:\n",
    "    #    group_names[group_key] = group_key\n",
    "\n",
    "    data_group = extract_athenagroup(data_prj._athena_groups[group_keys[0]])\n",
    "    if show_graph:    \n",
    "        # plot normalised mu on energy\n",
    "        # plot mu vs flat normalised mu for selected groups\n",
    "        #plt, data_group = plot_Nxmu_E(data_prj, group_keys, group_names)\n",
    "        plt = plot_normalised(data_group)\n",
    "        plt.show()\n",
    "    \n",
    "        \n",
    "    i_count +=1\n",
    "    \n",
    "    logging.info(\"Processed file: \"+ str(i_count) +\" \" + group_keys[0])\n",
    "    \n",
    "    if i_count == top_count:\n",
    "        break\n",
    "       \n",
    "logging.info(\"Finished processing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var =\"..\\\\cif_files\\\\C12O12Rh4.cif\"; \"FeS2.inp\"\n",
    "crystal_f = Path(var)\n",
    "print(crystal_f.name)\n",
    "print(crystal_f.parent)\n",
    "prefix = \"fes2\"\n",
    "feff_dir = var[:-4]+\"_feff\"\n",
    "feff_dir \n",
    "run_feff(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def select_paths(var = \"FeS2.inp\"):\n",
    "    crystal_f = Path(var)\n",
    "    feff_dir = crystal_f.name[:-4]+\"_feff\"\n",
    "    feff_inp = crystal_f.name[:-4]+\"_feff.inp\"\n",
    "    feff_files = \"files.dat\"\n",
    "    input_file = Path(feff_dir, feff_files)\n",
    "    #check if feff dir exists\n",
    "    if input_file.parent.exists() and input_file.exists():\n",
    "        logging.info(str(input_file.parent) + \" path and \"+ str(input_file)+ \" found\")\n",
    "    else:\n",
    "        logging.info(str(input_file.parent) + \" path not found, run feff before running select paths\")\n",
    "        return False\n",
    "    count = 0\n",
    "    # the .dat data is stored in fixed width strings \n",
    "    field_widths = [[0,13],[14,21],[22,31],[32,41],[42,48],[49,61]]\n",
    "    is_meta = True\n",
    "    data_headers = []\n",
    "    path_count = 0\n",
    "    paths_data = {}\n",
    "    logging.info(\"Reading from: \"+ str(input_file))\n",
    "    with open(input_file) as datfile:\n",
    "        dat_lines = datfile.readlines()\n",
    "        for a_line in dat_lines:\n",
    "            count += 1\n",
    "            if re.match('-*', a_line.strip()).group(0)!= '':\n",
    "                is_meta = False\n",
    "                logging.info(\"{}: {}\".format(count, a_line.strip()))\n",
    "            elif is_meta:\n",
    "                logging.info(\"{}: {}\".format(count, a_line.strip()))\n",
    "            elif data_headers == []:\n",
    "                data_headers = [a_line[s:e].strip().replace(' ','_') for s,e in field_widths]\n",
    "                logging.info(\"headers:\"+ str(data_headers))\n",
    "                print(path_count, a_line.strip())\n",
    "            else:\n",
    "                path_count += 1\n",
    "                data_values = [a_line[s:e].strip() for s,e in field_widths]\n",
    "                data_line = {}\n",
    "                for data_idx in range(0,len(data_headers)):\n",
    "                   data_line[data_headers[data_idx]] = data_values[data_idx]\n",
    "                print(path_count, a_line.strip())\n",
    "                paths_data[path_count] = data_line\n",
    "                \n",
    "select_paths('FeS2.inp')\n",
    "\n",
    "line_str = '    file        sig2   amp ratio    deg    nlegs  r effective '\n",
    "line_str = \" feff0001.dat 0.00000   100.000     6.000     2   2.2566\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20f509324cb046fcb4147e700358ce35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sheet(columns=5, layout=Layout(height='auto', width='auto'), rows=5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipysheet\n",
    "sheet = ipysheet.sheet()\n",
    "display(sheet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Paths\n",
    "The selection of scattering paths is shown in the following code. Each scattering path is loaded while setting the amplitude, $\\Delta E_0$, $\\Delta R$ and $\\sigma^2$ parameters using the GDS parameters defined previously.\n",
    "\n",
    "The groups are then added to a list of paths to be used for the fit.\n",
    "This task is different from the one in Demeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: ['1', \"'amp'\", \"'enot'\", \"'alpha*reff'\", \"'ss'\", '1'], 1: ['7', \"'amp'\", \"'enot'\", \"'alpha*reff'\", \"'ss2'\", '1'], 2: ['13', \"'amp'\", \"'enot'\", \"'alpha*reff'\", \"'ss3'\", '1'], 3: ['15', \"'amp'\", \"'enot'\", \"'alpha*reff'\", \"'ssfe'\", '1'], 4: ['1010', \"'amp'\", \"'enot'\", \"'alpha*reff'\", \"'ss*1.5'\", '1'], 5: ['1015', \"'amp'\", \"'enot'\", \"'alpha*reff'\", \"'ss/2+ssfe'\", '1'], 6: ['1005', \"'amp'\", \"'enot'\", \"'alpha*reff'\", \"'ss*2'\", '1'], 7: ['1000005', \"'amp'\", \"'enot'\", \"'alpha*reff'\", \"'ss*2'\", '1'], 8: ['1000001', \"'amp'\", \"'enot'\", \"'alpha*reff'\", \"'ss*4'\", '1']}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<FeffPath Group fes2_feff/feff0001.dat>,\n",
       " <FeffPath Group fes2_feff/feff0002.dat>,\n",
       " <FeffPath Group fes2_feff/feff0003.dat>,\n",
       " <FeffPath Group fes2_feff/feff0004.dat>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import library for managing csv files\n",
    "import csv\n",
    "\n",
    "# getting the data from the demeter csv_file, \n",
    "# with no headers does not work. We need an\n",
    "# alternative for using the FEFF data produced\n",
    "# by Larch\n",
    "\n",
    "def get_csv_no_id_no_head(input_file):\n",
    "    csv_data = {}\n",
    "    with open(input_file, newline='') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        row_id = 0\n",
    "        for row in reader:\n",
    "            csv_data[row_id]=row\n",
    "            row_id += 1\n",
    "    return csv_data\n",
    "\n",
    "# select paths\n",
    "# labelling for reference only using Artemis-FEFF given names\n",
    "def read_paths (sel_paths = 'FeS2_dmtr.csv', crystal_file = 'FeS2.inp'):\n",
    "    session = Interpreter()\n",
    "    csv_paths = get_csv_no_id_no_head(sel_paths)\n",
    "    print(csv_paths)\n",
    "    p_s1 = lp.xafs.FeffPathGroup(filename = 'fes2_feff/feff0001.dat',\n",
    "                                  label    = \"S1\",\n",
    "                                  s02      = 'amp',\n",
    "                                  e0       = 'enot',\n",
    "                                  sigma2   = 'ss',\n",
    "                                  deltar   = 'alpha*reff',\n",
    "                                  _larch   = session)\n",
    "    p_s2 = lp.xafs.FeffPathGroup(filename = 'fes2_feff/feff0002.dat',\n",
    "                                  label    = \"S2\",\n",
    "                                  s02      = 'amp',\n",
    "                                  e0       = 'enot',\n",
    "                                  sigma2   = 'ss2',\n",
    "                                  deltar   = 'alpha*reff',\n",
    "                                  _larch   = session)\n",
    "    p_s3 = lp.xafs.FeffPathGroup(filename = 'fes2_feff/feff0003.dat',\n",
    "                                  label    = \"S3\",\n",
    "                                  s02      = 'amp',\n",
    "                                  e0       = 'enot',\n",
    "                                  sigma2   = 'ss3',\n",
    "                                  deltar   = 'alpha*reff',\n",
    "                                  _larch   = session)\n",
    "    p_fe = lp.xafs.FeffPathGroup(filename = 'fes2_feff/feff0004.dat',\n",
    "                                  label    = \"Fe\",\n",
    "                                  s02      = 'amp',\n",
    "                                  e0       = 'enot',\n",
    "                                  sigma2   = 'ssfe',\n",
    "                                  deltar   = 'alpha*reff',\n",
    "                                  _larch   = session)\n",
    "    # return path list\n",
    "    return [p_s1, p_s2, p_s3, p_fe]\n",
    "\n",
    "selected_paths = read_paths()#sel_paths_f, crystal_file)\n",
    "selected_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: ['1', \"'amp'\", \"'enot'\", \"'alpha*reff'\", \"'ss'\", '1'], 1: ['7', \"'amp'\", \"'enot'\", \"'alpha*reff'\", \"'ss2'\", '1'], 2: ['13', \"'amp'\", \"'enot'\", \"'alpha*reff'\", \"'ss3'\", '1'], 3: ['15', \"'amp'\", \"'enot'\", \"'alpha*reff'\", \"'ssfe'\", '1'], 4: ['1010', \"'amp'\", \"'enot'\", \"'alpha*reff'\", \"'ss*1.5'\", '1'], 5: ['1015', \"'amp'\", \"'enot'\", \"'alpha*reff'\", \"'ss/2+ssfe'\", '1'], 6: ['1005', \"'amp'\", \"'enot'\", \"'alpha*reff'\", \"'ss*2'\", '1'], 7: ['1000005', \"'amp'\", \"'enot'\", \"'alpha*reff'\", \"'ss*2'\", '1'], 8: ['1000001', \"'amp'\", \"'enot'\", \"'alpha*reff'\", \"'ss*4'\", '1']}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td>1</td><td>2</td><td>3</td></tr><tr><td>4</td><td>5</td><td>6</td></tr><tr><td>7</td><td>8</td><td>9</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'tabulate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-3129f09a314f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m          \u001b[1;33m[\u001b[0m\u001b[1;34m\"Moon\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1737\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m73.5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m          [\"Mars\",3390,641.85]]\n\u001b[1;32m---> 23\u001b[1;33m \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mHTML\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtabulate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtabulate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtablefmt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'html'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'tabulate' is not defined"
     ]
    }
   ],
   "source": [
    "sel_paths = 'FeS2_dmtr.csv'\n",
    "csv_paths = get_csv_no_id_no_head(sel_paths)\n",
    "print(csv_paths)\n",
    "\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "data = [[1,2,3],\n",
    "        [4,5,6],\n",
    "        [7,8,9],\n",
    "        ]\n",
    "\n",
    "display(HTML(\n",
    "   '<table><tr>{}</tr></table>'.format(\n",
    "       '</tr><tr>'.join(\n",
    "           '<td>{}</td>'.format('</td><td>'.join(str(_) for _ in row)) for row in data)\n",
    "       )\n",
    "))\n",
    "\n",
    "table = [[\"Sun\",696000,1989100000],\n",
    "         [\"Earth\",6371,5973.6],\n",
    "         [\"Moon\",1737,73.5],\n",
    "         [\"Mars\",3390,641.85]]\n",
    "display(HTML(tabulate.tabulate(table, tablefmt='html')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Fit\n",
    "\n",
    "XAS fitting is performed in three steps:\n",
    "1. Create a Transform group to holds the set of Fourier transform parameters, fitting ranges, and space in which the data and sum of paths are to be compared (R space)\n",
    "2. Create a Dataset group,consistaining of the three components required for fitting(data, paths, and transform group)\n",
    "3. FEFFIT is run with the list of parameters (gds) for the fit, and the dataset or list of datasets groups.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run fit\n",
    "# create the transform grup (prepare the fit space).\n",
    "trans = lp.xafs.TransformGroup(fitspace='r', kmin=3, kmax=14, kw=2, dk=1, window='hanning', rmin=1.4,\n",
    "                               rmax=3.0, _larch=session)\n",
    "\n",
    "\n",
    "dset = lp.xafs.FeffitDataSet(data=data_group, pathlist=selected_paths, transform=trans, _larch=session)\n",
    "\n",
    "out = lp.xafs.feffit(gds, dset, _larch=session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review fit results\n",
    "The results of the fit are stored in the dataset. These can be plotted and printed as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(dset.data.r, dset.data.chir_mag, color='b')\n",
    "plt.plot(dset.data.r, dset.data.chir_re, color='b', label='expt.')\n",
    "plt.plot(dset.model.r, dset.model.chir_mag, color='r')\n",
    "plt.plot(dset.model.r, dset.model.chir_re, color='r', label='fit')\n",
    "plt.ylabel(\"Magnitude of Fourier Transform of $k^2 \\cdot \\chi$/$\\mathrm{\\AA}^{-3}$\")\n",
    "plt.xlabel(\"Radial distance/$\\mathrm{\\AA}$\")\n",
    "plt.xlim(0, 5)\n",
    "\n",
    "plt.fill([1.4, 1.4, 3.0, 3.0],[-3, 3, 3, -3], color='g',alpha=0.1)\n",
    "plt.text(2.35, -2.5, 'fit range')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 4))\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax2 = fig.add_subplot(122)\n",
    "# Creating the chifit plot from scratch\n",
    "#from larch.wxlib.xafsplots import plot_chifit\n",
    "#plot_chifit(dset, _larch=session)\n",
    "ax1.plot(dset.data.k, dset.data.chi*dset.data.k**2, color='b', label='expt.')\n",
    "ax1.plot(dset.model.k, dset.model.chi*dset.data.k**2 , color='r', label='fit')\n",
    "ax1.set_xlim(0, 15)\n",
    "ax1.set_xlabel(\"$k (\\mathrm{\\AA})^{-1}$\")\n",
    "ax1.set_ylabel(\"$k^2$ $\\chi (k)(\\mathrm{\\AA})^{-2}$\")\n",
    "ax1.fill([3.0, 3.0, 14.0, 14.0],[-3, 3, 3, -3], color='g',alpha=0.1)\n",
    "ax1.text(12.35, -2.5, 'fit range')\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(dset.data.r, dset.data.chir_mag, color='b', label='expt.')\n",
    "ax2.plot(dset.model.r, dset.model.chir_mag, color='r', label='fit')\n",
    "ax2.set_xlim(0, 5)\n",
    "ax2.set_xlabel(\"$R(\\mathrm{\\AA})$\")\n",
    "ax2.set_ylabel(\"$|\\chi(R)|(\\mathrm{\\AA}^{-3})$\")\n",
    "ax2.legend(loc='upper right')\n",
    "ax2.fill([1.4, 1.4, 3.0, 3.0],[0, 3, 3, 0], color='g',alpha=0.1)\n",
    "ax2.text(2.35, 2.75, 'fit range')\n",
    "plt.show()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lp.xafs.feffit_report(out, _larch=session))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars(gds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars(p_s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
