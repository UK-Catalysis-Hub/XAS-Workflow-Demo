{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproduce  H. Huang , et. al , Faraday Discuss., 2018, 208, 555 – 573 \n",
    "\n",
    "This notebook demonstrates reproducing the results of the paper with [Larch](https://xraypy.github.io/xraylarch/xafs/) using the corresponding published dataset (raw data). \n",
    "\n",
    "Huang, Haoliang, Nassr, Abu Bakr Ahmed Amine, Celorrio, Verónica, Taylor, S. F. Rebecca, Puthiyapura, Vinod Kumar, Hardacre, Christopher, Brett, Dan J. L., Russell, Andrea E. (2018) **Effects of heat treatment atmosphere on the structure and activity of Pt3Sn nanoparticle electrocatalysts: a characterisation case study.** Faraday Discussions. V. 208. pp. 555-573. DOI: [10.1039/c7fd00221a](https://doi.org/10.1039/c7fd00221a).\n",
    "\n",
    "- **Corresponding author**: Russell, Andrea E.\n",
    "- **E-mail**: a.e.russell@soton.ac.uk\n",
    "\n",
    "The data used for reproducing the results was published in the Southampton Instituional Repository [10.5258/SOTON/D0408](https://eprints.soton.ac.uk/421798/), with the name Xray_data.zip - Dataset.\n",
    "\n",
    "\n",
    "For more details about Larch, see [Larch Website](https://xraypy.github.io/xraylarch/xafs/)\n",
    "\n",
    "|CDI Entity  |Link       |DOI|\n",
    "|:-----------|:----------|:---|\n",
    "|Publication |[cdi_pub:37](http://cdi.ukcatalysishub.org/articles/37)|[10.1039/c7fd00221a](https://doi.org/10.1039/c7fd00221a) |\n",
    "|Data Object |[cdi_do:537](http://cdi.ukcatalysishub.org/datasets/537)|[10.5258/SOTON/D0408](https://eprints.soton.ac.uk/421798/)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproduce Figure 4 - XANES Analysis\n",
    "The first set of XAS results in the paper are in [Figure 4](https://pubs.rsc.org/image/article/2018/fd/c7fd00221a/c7fd00221a-f4_hi-res.gif)\n",
    "\n",
    "To reproduce this image we need to:\n",
    "- A: Identify the XANES data used (SnO2, Air, Ar, H2 and Sn foil)\n",
    "  - Plot normalised flattened mE of the spectra on the range 29190 – 29450 \n",
    "  - Plot first derivate of the spectra on the range 29190 – 29215\n",
    "- B: Take Sn foil and SnO2 and do LCF of the peaks against H2, Ar, and Air\n",
    "- C: Take Sn K-Edge of H2/H2 and SnO2 and do LCF of the peaks against H2, Ar, and Air\n",
    "\n",
    "|Key|Content|\n",
    "|:--|:--|\n",
    "|OC|parent|\n",
    "|OCA| Ar treated|\n",
    "|OCH| H2 treated|\n",
    "|OCO|air-treated|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Library with the functions that rplicate those provided by athena\n",
    "# normalisation, merging, re-binning, LCF\n",
    "# and visualisation (plotting)\n",
    "import lib.manage_athena as athenamgr  \n",
    "\n",
    "# File handling\n",
    "from pathlib import Path\n",
    "\n",
    "#plotting library\n",
    "import matplotlib.pyplot as plt\n",
    "# inline: shows plot in notebook\n",
    "# tk: shows plot in popup\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input parameters (variables)\n",
    "The variables in the next cell are the processing values that indicate where to get the data from, the pattern of the files to process and the number of files to process. These can be changed to process different datasets.\n",
    "\n",
    "### Column and group names.\n",
    "\n",
    "Knowing the elements of the input data set it is possible to start manipulating and visualising the XAFS data. \n",
    "\n",
    "In this case energy and $\\mu$ are provided, but the names of the columns do not match the names used by Larch provinding the custom column names. \n",
    "\n",
    "We rename the columns. The name of the groups is the same as the name of the file. To make things easier we can also adjust the file name.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables that can be changed to process different datasets\n",
    "data_path = \"./wf_data/pub_037/XAFS_prj/Sn K-edge/ascii\"\n",
    "\n",
    "data_mappings={\"PtSn\":  \"*_PtSn_OC_A*\",\n",
    "              \"Air\":  \"*_PtSn_OCO_A*\",\n",
    "              \"Ar\":  \"*_PtSn_OCA_A*\",\n",
    "              \"H2\":  \"*_PtSn_OCH_A*\",\n",
    "              \"PtSn H\":  \"*_PtSn_OC_H*\", \n",
    "              \"Air H\":  \"*_PtSn_OCO_H*\",\n",
    "              \"Ar H\":  \"*_PtSn_OCA_H*\",\n",
    "              \"H2 H\":  \"*_PtSn_OCH_H*\",}\n",
    "\n",
    "f_prefix = \"PtSn_KEdge\"\n",
    "column_labels = \"energy time I0 It Iref  mu lnItIref\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data and merge results for each sample in list\n",
    "The below reads the raw readings for eache of the samples in data mappings and merges them to create the signals to be processed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# start processing createa an output dir and sets the logger\n",
    "source_path, out_path = athenamgr.files_setup(f_prefix, data_path)\n",
    "print(\"Source:\", source_path, \"Output:\", out_path)\n",
    "\n",
    "\n",
    "merged_results={}\n",
    "# read all samples, merge and then normalise\n",
    "for a_sample in data_mappings:\n",
    "    files_list = athenamgr.get_files_list(source_path, data_mappings[a_sample])\n",
    "\n",
    "    # read the files for each sample\n",
    "    sample_list = []\n",
    "    for i_count, a_file  in enumerate(files_list):\n",
    "        file_name = a_file.name\n",
    "        f_suffix = str(i_count).zfill(4) \n",
    "        p_name = f_prefix+f_suffix\n",
    "        p_path = Path(out_path , p_name + \".prj\")\n",
    "        a_group = athenamgr.read_text(a_file, column_labels)\n",
    "        sample_list.append(a_group)\n",
    "        \n",
    "    # merge readings for sample\n",
    "    merged_xas = athenamgr.merge_readings(sample_list)\n",
    "\n",
    "    # rename group (same as the file name)\n",
    "    merged_xas.filename = a_sample\n",
    "    merged_results[a_sample] = merged_xas\n",
    "    # calculate pre-edge and post edge and add them to group\n",
    "    # using defaults\n",
    "    xas_data = athenamgr.fit_pre_post_edge(merged_xas)\n",
    "\n",
    "# results in the paper are recalibrated to 29204\n",
    "recalibrate_e0_to = 29204\n",
    "\n",
    "for a_sample in merged_results:\n",
    "    merged_results[a_sample] = athenamgr.recalibrate_energy(merged_results[a_sample], recalibrate_e0_to)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get standards\n",
    "The code below reads the Sn Foil and SnO2 project and retrieves the foil data used to copare to the readings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the Sn foil from project:\n",
    "sn_foil = \"./wf_data/pub_037/XAFS_prj/Sn foil.prj\"\n",
    "# read the input file \n",
    "sn_foil_prj = athenamgr.read_project(sn_foil)\n",
    "\n",
    "sn_foil_group = athenamgr.get_group(sn_foil_prj, 'merge')\n",
    "sn_foil_group.filename = \"Sn Foil\"\n",
    "sn_foil_group = athenamgr.recalibrate_energy(sn_foil_group, recalibrate_e0_to)\n",
    "merged_results[\"Sn Foil\"] = sn_foil_group\n",
    "\n",
    "# get the Sn O2 standard from project:\n",
    "sno2 = \"./wf_data/pub_037/XAFS_prj/SnO2 0.9 2.6-13.5 gbkg.prj\"\n",
    "# read the input file \n",
    "sno2_prj = athenamgr.read_project(sno2)\n",
    "\n",
    "sno2_group = athenamgr.get_group(sno2_prj, \"SnO2_0_9_2_6_13_5_0_8_1_0_with_theory\")#'SnO2_0_9')\n",
    "sno2_group.filename = \"SnO2\"\n",
    "sno2_group = athenamgr.recalibrate_energy(sno2_group, recalibrate_e0_to)\n",
    "merged_results[\"SnO2\"] = sno2_group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the mu signals for the reading and the Sn Foil (Figure 4A)\n",
    "\n",
    "These are the plots shown on Fig. 4 A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "include_groups = [\"Air\", \"Ar\", \"H2\", \"Sn Foil\", \"SnO2\"]\n",
    "for a_sample in merged_results:\n",
    "    if merged_results[a_sample].filename in include_groups:\n",
    "        plt = athenamgr.plot_normalised(merged_results[a_sample])\n",
    "    \n",
    "plt.xlim([29180, 29400])\n",
    "plt.show()\n",
    "\n",
    "for a_sample in merged_results:\n",
    "    if merged_results[a_sample].filename in include_groups:\n",
    "        plt = athenamgr.plot_derivative(merged_results[a_sample])\n",
    "    \n",
    "plt.xlim([29190, 29210])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear combination fitting - LCF (Figure 4 A and B)\n",
    "Lineal combination fitting with defaults for the H2, Ar and Air readings (Shown on Fig. 4 B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import custom plot functions (replicate plots in paper)\n",
    "import paper01_plots as c_plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lcf_components = [merged_results[\"Sn Foil\"],merged_results[\"SnO2\"]] # List of groups to use as components \n",
    "\n",
    "r_H2 = athenamgr.lcf_group(merged_results[\"H2\"], lcf_components)\n",
    "r_Ar = athenamgr.lcf_group(merged_results[\"Ar\"], lcf_components)\n",
    "r_Air = athenamgr.lcf_group(merged_results[\"Air\"], lcf_components)\n",
    "\n",
    "c_plots.compare_lcf_plot([merged_results[\"H2\"],r_H2], [merged_results[\"Ar\"],r_Ar], [merged_results[\"Air\"],r_Air])\n",
    "plt.show()\n",
    "\n",
    "print(r_H2.arrayname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_HH2 = athenamgr.lcf_group(merged_results[\"H2 H\"], lcf_components)\n",
    "r_HAr = athenamgr.lcf_group(merged_results[\"Ar H\"], lcf_components)\n",
    "r_HAir = athenamgr.lcf_group(merged_results[\"Air H\"], lcf_components)\n",
    "\n",
    "c_plots.compare_lcf_plot([merged_results[\"H2 H\"],r_HH2], [merged_results[\"Ar H\"],r_HAr], [merged_results[\"Air H\"],r_HAir])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Goodness of LCF fits\")\n",
    "print (\"LCF for H2:\\t\", \"%.4f\" % r_H2.rfactor)\n",
    "print (\"LCF for Ar:\\t\", \"%.4f\" % r_Ar.rfactor)\n",
    "print (\"LCF for Air:\\t\", \"%.4f\" % r_Air.rfactor)\n",
    "print (\"LCF for H\\\\H2:\\t\",\"%.4f\" % r_HH2.rfactor)\n",
    "print (\"LCF for H\\\\Ar:\\t\",\"%.4f\" % r_HAr.rfactor)\n",
    "print (\"LCF for H\\\\Air:\\t\",\"%.4f\" % r_HAir.rfactor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproduce Figure 5 XAS Processing\n",
    "Rebin is required for XAS processing (see [Athena Manual](https://bruceravel.github.io/demeter/documents/Athena/process/rebin.html). So after the XANES analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rebin Ar, Air and H2 Samples \n",
    "rebin_labels = [\"H2\", \"Ar\", \"Air\"]\n",
    "rebinned_groups = {}\n",
    "rebinned_gr=None\n",
    "for a_sample in merged_results:\n",
    "    if a_sample in rebin_labels:\n",
    "        rebinned_gr = athenamgr.rebin_group(merged_results[a_sample])\n",
    "        rebinned_gr.arrayname = a_sample+\" Rebbined\"\n",
    "        rebinned_groups[a_sample+\" Rebbined\"] = rebinned_gr\n",
    "        print(a_sample, \"rebinned to\" , len(rebinned_gr.energy),\"from\", len(merged_results[\"Ar\"].energy))\n",
    "\n",
    "athenamgr.save_groups([rebinned_groups[\"H2 Rebbined\"],rebinned_groups[\"Ar Rebbined\"],rebinned_groups[\"Air Rebbined\"]], \"rebinned.prj\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the input file \n",
    "athena_prj = athenamgr.read_project(\"rebinned.prj\")\n",
    "\n",
    "athena_groups = athenamgr.get_groups(athena_prj)\n",
    "\n",
    "group_names = []\n",
    "for a_group in athena_groups:\n",
    "    group_names.append(a_group.label)\n",
    "    \n",
    "for a_group in athena_groups:\n",
    "    athenamgr.calc_with_defaults(a_group)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crystal files and fitting parameters\n",
    "\n",
    "Define the location of the crystal files to be used in fitting.\n",
    "The fitting parameters can also be changed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting input variables\n",
    "# All crystals for this fit are stored at: \n",
    "#    C:/harwell/PSDI_test/wf_data/pub_037/additional/\n",
    "#       1692395a.cif  Pt3Sn for Sn\n",
    "#       1690711.cif   SnO2\n",
    "#       1680385.cif   PtO2\n",
    "#       1692395b.cif  Pt3Sn for Pt\n",
    "# new test replace Pt3Sn (1692395a.cif) with PtSn\n",
    "#       1692396.cif   PtSn for Sn \n",
    "\n",
    "\n",
    "crystal_files = [\"./wf_data/pub_037/additional/1690711.cif\",\n",
    "                 \"./wf_data/pub_037/additional/1692396.cif\",\n",
    "                 \"./wf_data/pub_037/additional/1680385.cif\",\n",
    "                 \"./wf_data/pub_037/additional/1692395b.cif\",] #\n",
    "\n",
    "gds_parms_f = \"SnK_edge_gds.csv\" # paths and parameters can\n",
    "sel_paths_f = \"SnK_edge_sp.csv\"  # be saved and retrieved.\n",
    "\n",
    "show_graph = False # False to prevent showing graphs\n",
    "\n",
    "# variables for fit\n",
    "fit_vars = {}\n",
    "fit_vars['fitspace']='r'\n",
    "fit_vars['kmin']=0 \n",
    "fit_vars['kmax']=10\n",
    "fit_vars['kw']=2 \n",
    "fit_vars['dk']=1\n",
    "fit_vars['window']='hanning'\n",
    "fit_vars['rmin']=0.0\n",
    "fit_vars['rmax']=5.0\n",
    "\n",
    "# Need to specify the absorbing atom and maximum radius\n",
    "absorbing_atoms = [\"Sn\",\"Sn\",\"O\",\"Pt\"]\n",
    "max_radius = 5.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Atoms and FEFF\n",
    "\n",
    "Larch does larch does not include a means for running atoms. Atoms is needed to get input for feff and calculate paths. Currently, the fastest option is to run Artemis to obtain the input (.inp) file for feff from a crystal file ('.cif' or '.inp')\n",
    "\n",
    "The code below shows how subprocess can be used to call perl, execute a small perl script that runs Artemis Atoms, and saves the output file ('inp') in a new directory.\n",
    "\n",
    "The file can then be used to run FEFF from Larch to calculate scattering paths.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Library with the functions that execute \n",
    "# Atoms and FEFF to generate scattering paths\n",
    "import lib.atoms_feff as feff_runner     \n",
    "\n",
    "# Set parameters          \n",
    "# library containign functions tho manage fit, at read, write \n",
    "# GDS parameters, and scattering paths. \n",
    "import lib.manage_fit as fit_manager  \n",
    "\n",
    "from larch import Interpreter\n",
    "session = Interpreter()\n",
    "\n",
    "# run feff and get a list of feff dirs\n",
    "feff_dirs = feff_runner.run_feff(crystal_files, absorbing_atoms, max_radius) \n",
    "\n",
    "# could prevent running if the files still exist and they are recent (<month old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read saved parameters from input gds file\n",
    "gds = fit_manager.read_gds(gds_parms_f, session)\n",
    "# show gsd group parameters in a spreadsheet\n",
    "this_sheet = fit_manager.show_gds(gds)\n",
    "# save gsd group parameters in a csv file\n",
    "fit_manager.save_gds(gds, gds_parms_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just in case something was changed\n",
    "# read the gds data and save it to the csv file \n",
    "gds = fit_manager.spreadsheet_to_gds(this_sheet, session)\n",
    "# save gsd group parameters in a csv file\n",
    "fit_manager.save_gds(gds, gds_parms_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Showa Select  FEFF paths\n",
    "\n",
    "To select a path change the value of the select column to 1 in the table displayed after running the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read saved selected paths from input file\n",
    "selected_paths = fit_manager.read_selected_paths_list(sel_paths_f, session)\n",
    "\n",
    "path_sheet = fit_manager.show_feff_paths(crystal_files, selected_paths)\n",
    "display(path_sheet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5.2 Assing parameters to selected paths\n",
    "\n",
    "To define the parameters enter values like those presented in the table below into the spreadsheet that appears after running the code in the following cell. The values should correspond to those defined as GDS parameters previously.\n",
    "\n",
    "|file                      |label    | s02 |e0   |sigma2 |deltar      |\n",
    "|:------------------------ |------   |-----|-----|-------|------------|\n",
    "|1690711_feff/feff0001.dat | O.Sn.1\t |amp  |enot |sssno  |alpha\\*reff |\n",
    "|1692396_feff/feff0001.dat | Pt.Sn.1 |amp  |enot |sssnpt |alpha\\*reff |\n",
    "|1680385_feff/feff0001.dat | Pn.O.1  |amp  |enot |sspto  |alpha\\*reff |\n",
    "|1692395b_feff/feff0001.dat| Pn.Pt.1 |amp  |enot |ssptpt |alpha\\*reff |\n",
    "|1692395b_feff/feff0002.dat| Sn.Pt.2 |amp  |enot |ssptsn |alpha\\*reff |\n",
    "\n",
    "\n",
    "**Note:** Labelling is used for reference only using Artemis-FEFF given names. Larch's FEFF does not label paths.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_sheet = fit_manager.show_selected_paths(path_sheet, selected_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_manager.save_selected_paths_list(sp_sheet, sel_paths_f)\n",
    "selected_paths = fit_manager.read_selected_paths_list(sel_paths_f, session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Run Fit\n",
    "\n",
    "XAS fitting is performed in three steps:\n",
    "\n",
    "1. Create a Transform group to hold the set of Fourier transform parameters, fitting ranges, and space in which the data and sum of paths are to be compared (R space)\n",
    "2. Create a Dataset group,consistaining of the three components required for fitting(data, paths, and transform group)\n",
    "3. FEFFIT is run with the list of parameters (gds) for the fit, and the dataset or list of datasets groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run fit\n",
    "fit_list = {}\n",
    "for a_group in athena_groups:\n",
    "    trans, dset, out = fit_manager.run_fit(a_group, gds, selected_paths, fit_vars, session)\n",
    "    fit_list[a_group.filename]=[trans, dset, out]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a_fit in fit_list:\n",
    "    chikr_p = c_plots.plot_markers(fit_list[a_fit][1],fit_vars['rmin'],fit_vars['rmax'],fit_vars['kmin'],fit_vars['kmax'], a_fit)\n",
    "    chikr_p.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a_fit in fit_list:\n",
    "    print(\"R-factor %.2f\"%(fit_list[a_fit][2].rfactor*100)+\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for a_fit in fit_list:\n",
    "    fit_report = fit_manager.get_fit_report(fit_list[a_fit][2], session)\n",
    "    print(fit_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproducibility of results\n",
    "\n",
    "All of the results can be reproduced. however there is a small issue regarding which crystal files to use. These are not included in the published dataset. \n",
    "\n",
    "Pending contactiong authors for validation of process.\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
